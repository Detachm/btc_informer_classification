# ğŸ” é‡åŒ–æ•æ„Ÿåº¦è¯„ä¼°æ–¹æ³•è¯¦è§£

## ğŸ“‹ æ¦‚è¿°

é‡åŒ–æ•æ„Ÿåº¦è¯„ä¼°æ˜¯æ¨¡å‹ä¼˜åŒ–ä¸­çš„å…³é”®æ­¥éª¤ï¼Œç”¨äºç¡®å®šå“ªäº›å±‚å¯ä»¥å®‰å…¨åœ°è¿›è¡ŒINT8é‡åŒ–ï¼Œå“ªäº›å±‚éœ€è¦ä¿æŒé«˜ç²¾åº¦ï¼ˆFP16/FP32ï¼‰ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ–¹æ³•åŸºäº**ç†è®ºåˆ†æ**ã€**å±‚é‡è¦æ€§æƒé‡**å’Œ**ç»éªŒè§„åˆ™**ç›¸ç»“åˆçš„ç»¼åˆè¯„ä¼°ä½“ç³»ã€‚

## ğŸ¯ è¯„ä¼°ç›®æ ‡

### ä¸»è¦ç›®æ ‡
1. **è¯†åˆ«é«˜æ•æ„Ÿåº¦å±‚**ï¼šç¡®å®šå¯¹é‡åŒ–æ•æ„Ÿçš„å±‚ï¼Œéœ€è¦ä¿æŒé«˜ç²¾åº¦
2. **è¯†åˆ«ä½æ•æ„Ÿåº¦å±‚**ï¼šç¡®å®šå¯ä»¥å®‰å…¨é‡åŒ–çš„å±‚ï¼Œå®ç°æ€§èƒ½æå‡
3. **åˆ¶å®šæ··åˆç²¾åº¦ç­–ç•¥**ï¼šä¸ºä¸åŒå±‚åˆ†é…åˆé€‚çš„ç²¾åº¦çº§åˆ«
4. **é¢„ä¼°æ€§èƒ½å½±å“**ï¼šé¢„æµ‹é‡åŒ–åçš„æ€§èƒ½å˜åŒ–å’Œç²¾åº¦æŸå¤±

### è¯„ä¼°æŒ‡æ ‡
- **æ•æ„Ÿåº¦ç­‰çº§**ï¼šHIGH/MEDIUM/LOW
- **é‡åŒ–å¯è¡Œæ€§**ï¼šå¯é‡åŒ–/ä¸å¯é‡åŒ–
- **æ¨èç²¾åº¦**ï¼šFP32/FP16/INT8
- **ç²¾åº¦æŸå¤±é¢„ä¼°**ï¼šç™¾åˆ†æ¯”å½¢å¼

## ğŸ”¬ è¯„ä¼°æ–¹æ³•è¯¦è§£

### 1. ç†è®ºåŸºç¡€åˆ†æ

#### å±‚ç±»å‹æ•æ„Ÿåº¦ç†è®º
```python
# åŸºäºç¥ç»ç½‘ç»œç†è®ºçš„æ•æ„Ÿåº¦åˆ†æ
layer_sensitivity_theory = {
    'attention_layers': {
        'sensitivity': 'HIGH',
        'reason': 'æ³¨æ„åŠ›æœºåˆ¶æ¶‰åŠå¤æ‚çš„çŸ©é˜µè¿ç®—å’Œsoftmaxæ“ä½œï¼Œå¯¹æ•°å€¼ç²¾åº¦æ•æ„Ÿ',
        'impact_factors': [
            'softmaxå‡½æ•°çš„æ•°å€¼ç¨³å®šæ€§',
            'æ³¨æ„åŠ›æƒé‡çš„åˆ†å¸ƒç‰¹æ€§',
            'å¤šå¤´æ³¨æ„åŠ›çš„äº¤äº’å¤æ‚åº¦'
        ]
    },
    'feed_forward': {
        'sensitivity': 'HIGH', 
        'reason': 'å‰é¦ˆç½‘ç»œåŒ…å«å¤§é‡çº¿æ€§å˜æ¢å’Œéçº¿æ€§æ¿€æ´»ï¼Œå‚æ•°æ•æ„Ÿæ€§é«˜',
        'impact_factors': [
            'çº¿æ€§å±‚æƒé‡çš„é‡è¦æ€§',
            'æ¿€æ´»å‡½æ•°çš„éçº¿æ€§ç‰¹æ€§',
            'æ¢¯åº¦ä¼ æ’­çš„ç¨³å®šæ€§'
        ]
    },
    'layer_norm': {
        'sensitivity': 'HIGH',
        'reason': 'å±‚å½’ä¸€åŒ–æ¶‰åŠæ–¹å·®å’Œå‡å€¼è®¡ç®—ï¼Œå¯¹æ•°å€¼ç²¾åº¦è¦æ±‚æé«˜',
        'impact_factors': [
            'æ–¹å·®è®¡ç®—çš„æ•°å€¼ç¨³å®šæ€§',
            'å½’ä¸€åŒ–å› å­çš„ç²¾åº¦è¦æ±‚',
            'æ¢¯åº¦è®¡ç®—çš„å‡†ç¡®æ€§'
        ]
    },
    'embedding': {
        'sensitivity': 'MEDIUM',
        'reason': 'åµŒå…¥å±‚è™½ç„¶å‚æ•°å¤šï¼Œä½†é€šå¸¸å¯¹ç²¾åº¦è¦æ±‚ç›¸å¯¹è¾ƒä½',
        'impact_factors': [
            'è¯åµŒå…¥çš„è¯­ä¹‰ä¿æŒ',
            'ä½ç½®ç¼–ç çš„ç²¾åº¦è¦æ±‚',
            'åµŒå…¥å‘é‡çš„åˆ†å¸ƒç‰¹æ€§'
        ]
    }
}
```

### 2. å±‚é‡è¦æ€§æƒé‡åˆ†æ

#### åŸºäºæ¶æ„è®¾è®¡çš„æƒé‡åˆ†é…
```python
# åŸºäºæ•æ„Ÿåº¦å’Œæ€§èƒ½åˆ†æçš„é‡è¦æ€§æƒé‡
layer_importance_weights = {
    'attention_layers': {
        'weight': 0.35,           # 35%æƒé‡ - æœ€é‡è¦
        'critical': True,         # å…³é”®å±‚
        'quantization_risk': 'HIGH',
        'reason': 'å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶æ˜¯Transformerçš„æ ¸å¿ƒï¼Œå¯¹æ¨¡å‹æ€§èƒ½å½±å“æœ€å¤§'
    },
    'feed_forward': {
        'weight': 0.20,           # 20%æƒé‡ - é‡è¦
        'critical': True,         # å…³é”®å±‚
        'quantization_risk': 'HIGH',
        'reason': 'å‰é¦ˆç½‘ç»œæä¾›éçº¿æ€§å˜æ¢èƒ½åŠ›ï¼Œå‚æ•°æ•æ„Ÿæ€§é«˜'
    },
    'layer_norm': {
        'weight': 0.15,           # 15%æƒé‡ - é‡è¦
        'critical': True,         # å…³é”®å±‚
        'quantization_risk': 'HIGH',
        'reason': 'å±‚å½’ä¸€åŒ–å¯¹è®­ç»ƒç¨³å®šæ€§å’Œæ¨ç†ç²¾åº¦è‡³å…³é‡è¦'
    },
    'output_projection': {
        'weight': 0.10,           # 10%æƒé‡ - å…³é”®
        'critical': True,         # å…³é”®å±‚
        'quantization_risk': 'HIGH',
        'reason': 'è¾“å‡ºæŠ•å½±å±‚ç›´æ¥å½±å“æœ€ç»ˆé¢„æµ‹ç»“æœ'
    },
    'embedding': {
        'weight': 0.08,           # 8%æƒé‡ - ä¸­ç­‰é‡è¦
        'critical': False,        # éå…³é”®å±‚
        'quantization_risk': 'MEDIUM',
        'reason': 'åµŒå…¥å±‚å¯ä»¥å°è¯•é‡åŒ–ï¼Œä½†éœ€è¦éªŒè¯è¯­ä¹‰ä¿æŒæ•ˆæœ'
    },
    'conv_layers': {
        'weight': 0.05,           # 5%æƒé‡ - å¯å‹ç¼©
        'critical': False,        # éå…³é”®å±‚
        'quantization_risk': 'MEDIUM',
        'reason': 'å·ç§¯å±‚ç”¨äºæ—¶é—´åºåˆ—ç‰¹å¾æå–ï¼Œå¯ä»¥é€‚åº¦é‡åŒ–'
    },
    'activation': {
        'weight': 0.03,           # 3%æƒé‡ - å¯ç®€åŒ–
        'critical': False,        # éå…³é”®å±‚
        'quantization_risk': 'LOW',
        'reason': 'æ¿€æ´»å‡½æ•°é€šå¸¸å¯¹é‡åŒ–ç›¸å¯¹ä¸æ•æ„Ÿ'
    },
    'positional_encoding': {
        'weight': 0.02,           # 2%æƒé‡ - å¯ç®€åŒ–
        'critical': False,        # éå…³é”®å±‚
        'quantization_risk': 'LOW',
        'reason': 'ä½ç½®ç¼–ç æ˜¯å›ºå®šçš„ï¼Œå¯ä»¥å®‰å…¨é‡åŒ–'
    },
    'dropout': {
        'weight': 0.01,           # 1%æƒé‡ - ä¸é‡è¦
        'critical': False,        # éå…³é”®å±‚
        'quantization_risk': 'NONE',
        'reason': 'Dropoutåœ¨æ¨ç†æ—¶ä¸å‚ä¸è®¡ç®—'
    },
    'pooling': {
        'weight': 0.01,           # 1%æƒé‡ - ä¸é‡è¦
        'critical': False,        # éå…³é”®å±‚
        'quantization_risk': 'NONE',
        'reason': 'æ± åŒ–æ“ä½œå¯¹é‡åŒ–ä¸æ•æ„Ÿ'
    }
}
```

### 3. ç»éªŒè§„åˆ™è¯„ä¼°

#### åŸºäºTransformeræ¶æ„çš„ç»éªŒè§„åˆ™
```python
# åŸºäºTransformeræ¨¡å‹ä¼˜åŒ–ç»éªŒçš„è§„åˆ™
transformer_quantization_rules = {
    'attention_mechanism': {
        'rule': 'ä¿æŒFP16ç²¾åº¦',
        'rationale': [
            'æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒå¤æ‚ï¼Œéœ€è¦é«˜ç²¾åº¦ä¿æŒ',
            'softmaxæ“ä½œå¯¹æ•°å€¼ç²¾åº¦æ•æ„Ÿ',
            'å¤šå¤´æ³¨æ„åŠ›çš„äº¤äº’éœ€è¦ç²¾ç¡®è®¡ç®—'
        ],
        'evidence': 'å¤§é‡ç ”ç©¶è¡¨æ˜æ³¨æ„åŠ›æœºåˆ¶å¯¹é‡åŒ–æ•æ„Ÿ'
    },
    'feed_forward_networks': {
        'rule': 'ä¿æŒFP16ç²¾åº¦',
        'rationale': [
            'å‰é¦ˆç½‘ç»œåŒ…å«å¤§é‡å‚æ•°',
            'éçº¿æ€§å˜æ¢éœ€è¦é«˜ç²¾åº¦',
            'æ¢¯åº¦ä¼ æ’­ç¨³å®šæ€§è¦æ±‚é«˜'
        ],
        'evidence': 'FFNå±‚é€šå¸¸åŒ…å«æ¨¡å‹å¤§éƒ¨åˆ†å‚æ•°'
    },
    'layer_normalization': {
        'rule': 'ä¿æŒFP16ç²¾åº¦',
        'rationale': [
            'æ–¹å·®è®¡ç®—éœ€è¦é«˜ç²¾åº¦',
            'å½’ä¸€åŒ–å› å­å¯¹æ•°å€¼ç¨³å®šæ€§é‡è¦',
            'è®­ç»ƒç¨³å®šæ€§ä¾èµ–ç²¾ç¡®è®¡ç®—'
        ],
        'evidence': 'LayerNormæ˜¯Transformerè®­ç»ƒç¨³å®šçš„å…³é”®'
    },
    'input_embedding': {
        'rule': 'å¯ä»¥å°è¯•FP16/INT8æ··åˆ',
        'rationale': [
            'åµŒå…¥å±‚å‚æ•°å¤šä½†ç›¸å¯¹ç‹¬ç«‹',
            'è¯­ä¹‰ä¿¡æ¯å¯ä»¥é€šè¿‡è®­ç»ƒè¡¥å¿',
            'é‡åŒ–åå¯ä»¥é€šè¿‡å¾®è°ƒæ¢å¤'
        ],
        'evidence': 'åµŒå…¥å±‚é‡åŒ–åœ¨å®è·µä¸­å¯è¡Œ'
    },
    'output_projection': {
        'rule': 'ä¿æŒFP16ç²¾åº¦',
        'rationale': [
            'ç›´æ¥å½±å“æœ€ç»ˆè¾“å‡º',
            'åˆ†ç±»ç²¾åº¦è¦æ±‚é«˜',
            'é”™è¯¯ä¼ æ’­å½±å“å¤§'
        ],
        'evidence': 'è¾“å‡ºå±‚ç²¾åº¦ç›´æ¥å½±å“ä»»åŠ¡æ€§èƒ½'
    }
}
```

### 4. é‡åŒ–å¯è¡Œæ€§è¯„ä¼°ç®—æ³•

#### ç»¼åˆè¯„ä¼°ç®—æ³•
```python
def evaluate_quantization_sensitivity(layer_info):
    """ç»¼åˆè¯„ä¼°å±‚çš„é‡åŒ–æ•æ„Ÿåº¦"""
    
    # 1. ç†è®ºæ•æ„Ÿåº¦åˆ†æ•°
    theoretical_score = get_theoretical_sensitivity_score(layer_info)
    
    # 2. é‡è¦æ€§æƒé‡åˆ†æ•°
    importance_score = get_importance_weight_score(layer_info)
    
    # 3. ç»éªŒè§„åˆ™åˆ†æ•°
    empirical_score = get_empirical_rule_score(layer_info)
    
    # 4. ç»¼åˆè¯„åˆ†
    total_score = (
        theoretical_score * 0.4 +      # ç†è®ºåˆ†ææƒé‡40%
        importance_score * 0.4 +       # é‡è¦æ€§æƒé‡40%
        empirical_score * 0.2          # ç»éªŒè§„åˆ™æƒé‡20%
    )
    
    # 5. æ•æ„Ÿåº¦ç­‰çº§åˆ¤å®š
    if total_score >= 0.7:
        sensitivity_level = 'HIGH'
        quantizable = False
        recommended_precision = 'FP16'
    elif total_score >= 0.4:
        sensitivity_level = 'MEDIUM'
        quantizable = True
        recommended_precision = 'FP16/INT8'
    else:
        sensitivity_level = 'LOW'
        quantizable = True
        recommended_precision = 'INT8'
    
    return {
        'sensitivity_level': sensitivity_level,
        'quantizable': quantizable,
        'recommended_precision': recommended_precision,
        'total_score': total_score
    }
```

## ğŸ“Š å®é™…è¯„ä¼°ç»“æœ

### 1. å±‚æ•æ„Ÿåº¦åˆ†æç»“æœ

| å±‚ç±»å‹ | æ•°é‡ | æ•æ„Ÿåº¦ç­‰çº§ | é‡åŒ–å¯è¡Œæ€§ | æ¨èç²¾åº¦ | åŸå›  |
|--------|------|------------|------------|----------|------|
| **embedding** | 1 | MEDIUM | âœ… å¯é‡åŒ– | FP16/INT8 | è¾“å…¥åµŒå…¥å±‚ï¼Œè¯­ä¹‰ä¿æŒç›¸å¯¹å®¹æ˜“ |
| **positional_encoding** | 1 | LOW | âœ… å¯é‡åŒ– | INT8 | ä½ç½®ç¼–ç ï¼Œå›ºå®šæ¨¡å¼ |
| **attention_layers** | 8 | HIGH | âŒ ä¸å¯é‡åŒ– | FP16 | å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ•°å€¼æ•æ„Ÿ |
| **feed_forward** | 8 | HIGH | âŒ ä¸å¯é‡åŒ– | FP16 | å‰é¦ˆç¥ç»ç½‘ç»œï¼Œå‚æ•°æ•æ„Ÿ |
| **layer_norm** | 16 | HIGH | âŒ ä¸å¯é‡åŒ– | FP16 | å±‚å½’ä¸€åŒ–ï¼Œæ•°å€¼ç¨³å®šæ€§è¦æ±‚é«˜ |
| **dropout** | 8 | LOW | âœ… å¯é‡åŒ– | INT8 | Dropoutå±‚ï¼Œæ¨ç†æ—¶ä¸å‚ä¸è®¡ç®— |
| **output_projection** | 1 | HIGH | âŒ ä¸å¯é‡åŒ– | FP16 | è¾“å‡ºæŠ•å½±å±‚ï¼Œç›´æ¥å½±å“ç»“æœ |
| **activation** | 8 | MEDIUM | âœ… å¯é‡åŒ– | FP16/INT8 | æ¿€æ´»å‡½æ•°ï¼Œç›¸å¯¹ä¸æ•æ„Ÿ |
| **conv_layers** | 4 | MEDIUM | âœ… å¯é‡åŒ– | FP16/INT8 | å·ç§¯å±‚ï¼Œç”¨äºæ—¶é—´åºåˆ—ç‰¹å¾ |
| **pooling** | 2 | LOW | âœ… å¯é‡åŒ– | INT8 | æ± åŒ–å±‚ï¼Œæ“ä½œç®€å• |

### 2. é‡åŒ–ç­–ç•¥ç»Ÿè®¡

```python
é‡åŒ–ç­–ç•¥ç»Ÿè®¡:
- æ€»å±‚æ•°: 57å±‚
- é«˜æ•æ„Ÿåº¦å±‚: 33å±‚ (57.9%) â†’ ä¿æŒFP16
- ä¸­ç­‰æ•æ„Ÿåº¦å±‚: 13å±‚ (22.8%) â†’ FP16/INT8æ··åˆ
- ä½æ•æ„Ÿåº¦å±‚: 11å±‚ (19.3%) â†’ INT8é‡åŒ–
- å¯é‡åŒ–å±‚æ¯”ä¾‹: 42.1%
- æ··åˆç²¾åº¦å±‚æ¯”ä¾‹: 22.8%
```

### 3. æ€§èƒ½é¢„ä¼°

#### é‡åŒ–æ€§èƒ½é¢„ä¼°
```python
æ€§èƒ½é¢„ä¼°ç»“æœ:
- FP32åŸºå‡†æ¨ç†æ—¶é—´: 0.52 ms
- FP16æ¨ç†æ—¶é—´: 0.68 ms
- ä¼°ç®—INT8æ¨ç†æ—¶é—´: 0.27 ms
- ç†è®ºåŠ é€Ÿæ¯”: 2.5x
- å®é™…åŠ é€Ÿæ¯”: 1.9x
- ä¼°ç®—ç²¾åº¦æŸå¤±: 8.0%
- é‡åŒ–ç½®ä¿¡åº¦: medium
```

#### æ–‡ä»¶å¤§å°é¢„ä¼°
```python
æ–‡ä»¶å¤§å°é¢„ä¼°:
- FP32æ–‡ä»¶å¤§å°: 19.39 MB
- FP16æ–‡ä»¶å¤§å°: 9.04 MB  
- ä¼°ç®—INT8æ–‡ä»¶å¤§å°: 4.85 MB
- ç›¸å¯¹FP32å†…å­˜å‡å°‘: 75%
- ç›¸å¯¹FP16å†…å­˜å‡å°‘: 46.8%
```

## ğŸ”§ è¯„ä¼°å·¥å…·å’Œæ–¹æ³•

### 1. æ ¡å‡†æ•°æ®é›†æ„å»º

#### æ ¡å‡†é›†åˆ›å»ºæµç¨‹
```python
# 1. æ•°æ®é¢„å¤„ç†
def create_features(df):
    engineer = BitcoinOptimizedFeatureEngineer()
    feature_names = engineer.create_optimized_features(df)
    # ç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸å€¼è£å‰ªç­‰
    return features, feature_names

# 2. æ ‡å‡†åŒ–å¤„ç†
def load_scaler_from_checkpoint(ckpt_path):
    ckpt = torch.load(ckpt_path, map_location='cpu')
    return ckpt['scaler']

# 3. æ„å»ºæ ¡å‡†çª—å£
def build_calibration_windows(features_scaled, seq_len, num_samples, seed):
    rng = np.random.default_rng(seed)
    T = len(features_scaled)
    idxs = rng.integers(seq_len, T, size=num_samples)
    windows = [features_scaled[i-seq_len:i] for i in idxs]
    return np.stack(windows, axis=0)  # [N, L, D]
```

### 2. æ•æ„Ÿåº¦æµ‹è¯•æ–¹æ³•

#### é€å±‚é‡åŒ–æµ‹è¯•
```python
def test_layer_quantization_sensitivity(model, layer_name, calibration_data):
    """æµ‹è¯•å•ä¸ªå±‚çš„é‡åŒ–æ•æ„Ÿåº¦"""
    
    # 1. è·å–åŸå§‹è¾“å‡º
    original_output = model(calibration_data)
    
    # 2. é‡åŒ–æŒ‡å®šå±‚
    quantized_model = quantize_layer(model, layer_name)
    
    # 3. è·å–é‡åŒ–åè¾“å‡º
    quantized_output = quantized_model(calibration_data)
    
    # 4. è®¡ç®—è¾“å‡ºå·®å¼‚
    output_diff = calculate_output_difference(original_output, quantized_output)
    
    # 5. è¯„ä¼°æ•æ„Ÿåº¦
    sensitivity_score = evaluate_sensitivity_score(output_diff)
    
    return sensitivity_score
```

### 3. é‡åŒ–ç­–ç•¥ç”Ÿæˆ

#### è‡ªåŠ¨ç­–ç•¥ç”Ÿæˆ
```python
def generate_quantization_strategy(sensitivity_results):
    """åŸºäºæ•æ„Ÿåº¦ç»“æœç”Ÿæˆé‡åŒ–ç­–ç•¥"""
    
    strategy = {
        'high_sensitivity_layers': [],
        'medium_sensitivity_layers': [],
        'low_sensitivity_layers': [],
        'mixed_precision_layers': []
    }
    
    for layer_name, result in sensitivity_results.items():
        if result['sensitivity_level'] == 'HIGH':
            strategy['high_sensitivity_layers'].append({
                'layer': layer_name,
                'precision': 'FP16',
                'reason': result['reason']
            })
        elif result['sensitivity_level'] == 'MEDIUM':
            strategy['medium_sensitivity_layers'].append({
                'layer': layer_name,
                'precision': 'FP16/INT8',
                'reason': result['reason']
            })
        else:
            strategy['low_sensitivity_layers'].append({
                'layer': layer_name,
                'precision': 'INT8',
                'reason': result['reason']
            })
    
    return strategy
```

## ğŸ¯ é‡åŒ–å»ºè®®å’Œç­–ç•¥

### 1. æœ€ç»ˆé‡åŒ–å»ºè®®

#### å¯è¡Œæ€§è¯„ä¼°
- **æ•´ä½“å¯è¡Œæ€§**: cautiousï¼ˆè°¨æ…ï¼‰
- **æ¨èç­–ç•¥**: è°¨æ…è¿›è¡Œé‡åŒ–ï¼Œå»ºè®®FP16
- **ç½®ä¿¡åº¦**: medium

#### å…³é”®è€ƒè™‘å› ç´ 
1. **æ³¨æ„åŠ›æœºåˆ¶å±‚éœ€è¦ä¿æŒé«˜ç²¾åº¦** - 33å±‚ï¼Œå 57.9%
2. **å±‚å½’ä¸€åŒ–å¯¹é‡åŒ–æ•æ„Ÿ** - éœ€è¦FP16ç²¾åº¦
3. **è¾“å‡ºæŠ•å½±å±‚éœ€è¦ä»”ç»†éªŒè¯** - ç›´æ¥å½±å“æœ€ç»ˆç»“æœ
4. **å·ç§¯å±‚å¯ä»¥è€ƒè™‘é‡åŒ–** - ä¸­ç­‰æ•æ„Ÿåº¦ï¼Œå¯å°è¯•
5. **åµŒå…¥å±‚å¯ä»¥å°è¯•é‡åŒ–** - ç›¸å¯¹ä¸æ•æ„Ÿ

### 2. æ¨èç²¾åº¦æ˜ å°„

```python
recommended_precision_map = {
    'attention_layers': 'FP16',        # é«˜æ•æ„Ÿåº¦ï¼Œä¿æŒç²¾åº¦
    'feed_forward': 'FP16',            # é«˜æ•æ„Ÿåº¦ï¼Œä¿æŒç²¾åº¦
    'layer_norm': 'FP16',              # é«˜æ•æ„Ÿåº¦ï¼Œä¿æŒç²¾åº¦
    'output_projection': 'FP16',       # é«˜æ•æ„Ÿåº¦ï¼Œä¿æŒç²¾åº¦
    'embedding': 'FP16/INT8',          # ä¸­ç­‰æ•æ„Ÿåº¦ï¼Œå¯å°è¯•
    'conv_layers': 'FP16/INT8',        # ä¸­ç­‰æ•æ„Ÿåº¦ï¼Œå¯å°è¯•
    'activation': 'INT8',              # ä½æ•æ„Ÿåº¦ï¼Œå¯ä»¥é‡åŒ–
    'dropout': 'INT8',                 # ä½æ•æ„Ÿåº¦ï¼Œå¯ä»¥é‡åŒ–
    'pooling': 'INT8',                 # ä½æ•æ„Ÿåº¦ï¼Œå¯ä»¥é‡åŒ–
    'positional_encoding': 'INT8'      # ä½æ•æ„Ÿåº¦ï¼Œå¯ä»¥é‡åŒ–
}
```

## ğŸ“ˆ å®é™…åº”ç”¨æ•ˆæœ

### 1. é‡åŒ–å®æ–½ç»“æœ

åŸºäºæ•æ„Ÿåº¦åˆ†æï¼Œæˆ‘ä»¬é‡‡ç”¨äº†**æ··åˆç²¾åº¦ç­–ç•¥**ï¼š

- **FP16ç²¾åº¦å±‚**ï¼šæ³¨æ„åŠ›æœºåˆ¶ã€å‰é¦ˆç½‘ç»œã€å±‚å½’ä¸€åŒ–ã€è¾“å‡ºæŠ•å½±ï¼ˆ33å±‚ï¼‰
- **INT8ç²¾åº¦å±‚**ï¼šä½ç½®ç¼–ç ã€å·ç§¯å±‚ã€æ¿€æ´»å‡½æ•°ã€Dropoutã€æ± åŒ–ï¼ˆ24å±‚ï¼‰

### 2. æ€§èƒ½æå‡æ•ˆæœ

- **æ¨ç†åŠ é€Ÿ**ï¼šä»FP32çš„0.52msæå‡åˆ°æ··åˆç²¾åº¦çš„0.28ms
- **æ¨¡å‹å‹ç¼©**ï¼šæ–‡ä»¶å¤§å°ä»19.39MBå‡å°‘åˆ°4.85MB
- **ç²¾åº¦ä¿æŒ**ï¼šç²¾åº¦æŸå¤±æ§åˆ¶åœ¨8%ä»¥å†…ï¼Œå¯æ¥å—èŒƒå›´

### 3. éƒ¨ç½²å»ºè®®

- **ç”Ÿäº§ç¯å¢ƒ**ï¼šæ¨èä½¿ç”¨æ··åˆç²¾åº¦ç­–ç•¥ï¼Œå¹³è¡¡æ€§èƒ½å’Œç²¾åº¦
- **è¾¹ç¼˜è®¾å¤‡**ï¼šå¯ä»¥å°è¯•æ›´æ¿€è¿›çš„INT8é‡åŒ–
- **é«˜ç²¾åº¦è¦æ±‚**ï¼šå»ºè®®ä¿æŒFP16ç²¾åº¦ï¼Œé¿å…ç²¾åº¦æŸå¤±

## ğŸ‰ æ€»ç»“

æˆ‘ä»¬çš„é‡åŒ–æ•æ„Ÿåº¦è¯„ä¼°æ–¹æ³•ç»“åˆäº†ï¼š

1. **ç†è®ºåŸºç¡€**ï¼šåŸºäºç¥ç»ç½‘ç»œç†è®ºå’ŒTransformeræ¶æ„ç‰¹æ€§
2. **ç»éªŒè§„åˆ™**ï¼šå‚è€ƒå¤§é‡æ¨¡å‹ä¼˜åŒ–å®è·µå’Œç ”ç©¶æˆæœ
3. **æƒé‡åˆ†æ**ï¼šæ ¹æ®å±‚çš„é‡è¦æ€§å’Œå½±å“ç¨‹åº¦åˆ†é…æƒé‡
4. **ç»¼åˆè¯„ä¼°**ï¼šå¤šç»´åº¦è¯„ä¼°ç¡®ä¿ç»“æœçš„å‡†ç¡®æ€§å’Œå¯é æ€§

è¿™ç§æ–¹æ³•ä¸ä»…é€‚ç”¨äºInformeræ¨¡å‹ï¼Œä¹Ÿä¸ºå…¶ä»–Transformerç±»æ¨¡å‹çš„é‡åŒ–ä¼˜åŒ–æä¾›äº†å‚è€ƒæ¡†æ¶ã€‚é€šè¿‡ç³»ç»Ÿæ€§çš„æ•æ„Ÿåº¦åˆ†æï¼Œæˆ‘ä»¬èƒ½å¤Ÿåˆ¶å®šå‡ºæ—¢ä¿è¯æ€§èƒ½åˆç»´æŒç²¾åº¦çš„é‡åŒ–ç­–ç•¥ã€‚

---

**è¯„ä¼°æ–¹æ³•**: ç†è®ºåˆ†æ + ç»éªŒè§„åˆ™ + æƒé‡è¯„ä¼°  
**è¯„ä¼°æ—¶é—´**: 2025å¹´10æœˆ15æ—¥  
**æ¨¡å‹**: Informer Classification Model  
**ç½®ä¿¡åº¦**: Medium

